/**
 * Re-ingest all TSE 2026 Government Plans with improved pipeline
 *
 * This script re-processes all documents with:
 * - Enhanced text cleaning (page markers, encoding fixes)
 * - Optimized chunk sizes (400-600 tokens)
 * - Page metadata enrichment
 *
 * IMPORTANT: This will replace existing chunks in the database
 */

import { IngestPipeline } from '../ingest/components/IngestPipeline.js';
import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';
import readline from 'readline';

dotenv.config();

const TSE_PLANS = [
  {
    documentId: 'pln-2026',
    partyName: 'Partido Liberaci√≥n Nacional',
    partyId: 'PLN',
    url: 'https://www.tse.go.cr/2026/docus/planesgobierno/PLN.pdf'
  },
  {
    documentId: 'pac-2026',
    partyName: 'Partido Acci√≥n Ciudadana',
    partyId: 'PAC',
    url: 'https://www.tse.go.cr/2026/docus/planesgobierno/PAC.pdf'
  },
  {
    documentId: 'pusc-2026',
    partyName: 'Partido Unidad Social Cristiana',
    partyId: 'PUSC',
    url: 'https://www.tse.go.cr/2026/docus/planesgobierno/PUSC.pdf'
  },
  {
    documentId: 'prsc-2026',
    partyName: 'Partido Restauraci√≥n Social Cristiana',
    partyId: 'PRSC',
    url: 'https://www.tse.go.cr/2026/docus/planesgobierno/PRSC.pdf'
  },
  {
    documentId: 'pfa-2026',
    partyName: 'Partido Frente Amplio',
    partyId: 'PFA',
    url: 'https://www.tse.go.cr/2026/docus/planesgobierno/PFA.pdf'
  },
];

async function confirmReingest(): Promise<boolean> {
    const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
    });

    return new Promise((resolve) => {
        rl.question('\n‚ö†Ô∏è  This will DELETE and REPLACE all existing chunks. Continue? (yes/no): ', (answer) => {
            rl.close();
            resolve(answer.toLowerCase() === 'yes');
        });
    });
}

async function clearExistingChunks(documentId: string) {
    const supabase = createClient(
        process.env.SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
    );

    console.log(`   üóëÔ∏è  Deleting existing chunks for ${documentId}...`);

    // First, get the document UUID
    const { data: docs, error: docError } = await supabase
        .from('documents')
        .select('id')
        .eq('document_id', documentId)
        .single();

    if (docError || !docs) {
        console.log(`   ‚ÑπÔ∏è  No existing document found (this is OK for first ingestion)`);
        return;
    }

    const documentUuid = docs.id;

    // Delete chunks for this document UUID
    const { error: deleteError } = await supabase
        .from('chunks')
        .delete()
        .eq('document_id', documentUuid);

    if (deleteError) {
        console.log(`   ‚ö†Ô∏è  Warning: Could not delete chunks: ${deleteError.message}`);
    } else {
        console.log(`   ‚úÖ Existing chunks deleted`);
    }
}

async function main() {
    console.log('üîÑ Re-ingesting all TSE 2026 Government Plans');
    console.log(`   Total plans: ${TSE_PLANS.length}`);
    console.log('   Using improved pipeline with:');
    console.log('     - Page marker extraction');
    console.log('     - Enhanced encoding fixes');
    console.log('     - Optimized chunk sizes (400-600 tokens)');
    console.log('     - Page metadata enrichment\n');

    const confirmed = await confirmReingest();

    if (!confirmed) {
        console.log('\n‚ùå Re-ingestion cancelled by user\n');
        return;
    }

    console.log('\n‚úÖ Starting re-ingestion...\n');

    const pipeline = new IngestPipeline();
    const results = [];
    let successCount = 0;
    let failCount = 0;

    const overallStartTime = Date.now();

    for (let i = 0; i < TSE_PLANS.length; i++) {
        const plan = TSE_PLANS[i];
        const planNum = i + 1;

        console.log(`\n${'='.repeat(80)}`);
        console.log(`üìÑ [${planNum}/${TSE_PLANS.length}] ${plan.partyName} (${plan.partyId})`);
        console.log(`${'='.repeat(80)}\n`);

        const startTime = Date.now();

        try {
            // Clear existing chunks first
            await clearExistingChunks(plan.documentId);

            // Re-ingest with improved pipeline
            const result = await pipeline.ingest(
                plan.url,
                plan.documentId,
                {
                    generateEmbeddings: true,
                    storeInVectorDB: true,
                    chunkingOptions: {
                        chunkSize: 400,
                        maxChunkSize: 600,
                        overlapSize: 50
                    }
                }
            );

            const duration = Date.now() - startTime;

            if (result.success && result.chunks) {
                successCount++;

                // Calculate stats
                const tokenCounts = result.chunks.map(c => c.tokens);
                const avgTokens = tokenCounts.reduce((a, b) => a + b, 0) / tokenCounts.length;
                const chunksWithPages = result.chunks.filter(c => c.pageNumber || c.pageRange);

                console.log(`\n‚úÖ SUCCESS - ${plan.partyId}`);
                console.log(`   Chunks: ${result.chunks.length}`);
                console.log(`   Avg tokens: ${avgTokens.toFixed(0)}`);
                console.log(`   With page info: ${chunksWithPages.length}/${result.chunks.length}`);
                console.log(`   Time: ${(duration / 1000).toFixed(1)}s`);
            } else {
                failCount++;
                console.log(`\n‚ùå FAILED - ${plan.partyId}`);
                console.log(`   Error: ${result.error}`);
            }

            results.push({
                ...plan,
                success: result.success,
                chunks: result.chunks?.length || 0,
                duration,
                error: result.error,
            });

        } catch (error) {
            failCount++;
            const duration = Date.now() - startTime;
            console.log(`\n‚ùå EXCEPTION - ${plan.partyId}`);
            console.log(`   Error: ${error instanceof Error ? error.message : String(error)}`);

            results.push({
                ...plan,
                success: false,
                chunks: 0,
                duration,
                error: error instanceof Error ? error.message : String(error),
            });
        }
    }

    pipeline.dispose();

    const totalDuration = Date.now() - overallStartTime;

    // Summary
    console.log(`\n${'='.repeat(80)}`);
    console.log('üìä RE-INGESTION SUMMARY');
    console.log(`${'='.repeat(80)}\n`);

    console.log(`Total plans processed: ${TSE_PLANS.length}`);
    console.log(`‚úÖ Successful: ${successCount}`);
    console.log(`‚ùå Failed: ${failCount}`);
    console.log(`‚è±Ô∏è  Total time: ${(totalDuration / 1000 / 60).toFixed(1)} minutes\n`);

    console.log('Detailed results:\n');
    results.forEach((r) => {
        const status = r.success ? '‚úÖ' : '‚ùå';
        const time = (r.duration / 1000).toFixed(1);
        console.log(`${status} ${r.partyId.padEnd(6)} | ${r.chunks.toString().padStart(3)} chunks | ${time.padStart(5)}s | ${r.partyName}`);
        if (!r.success && r.error) {
            console.log(`   ‚îî‚îÄ Error: ${r.error.substring(0, 100)}...`);
        }
    });

    const totalChunks = results.reduce((sum, r) => sum + r.chunks, 0);
    console.log(`\nüì¶ Total chunks created: ${totalChunks}`);
    console.log(`üìà Average chunks per plan: ${(totalChunks / successCount).toFixed(0)}`);

    if (failCount === 0) {
        console.log(`\nüéâ All plans re-ingested successfully!`);
        console.log(`\nüí° Next steps:`);
        console.log(`   1. Test search quality with: pnpm tsx test-query.ts "¬øQu√© dice el PUSC sobre econom√≠a?"`);
        console.log(`   2. Check improved similarity scores`);
        console.log(`   3. Verify page metadata is present in results`);
    } else {
        console.log(`\n‚ö†Ô∏è  ${failCount} plan(s) failed. Check errors above.`);
    }

    console.log('\n‚úÖ Re-ingestion complete!\n');
}

main().catch((error) => {
    console.error('\n‚ùå Fatal error during re-ingestion:');
    console.error(error);
    process.exit(1);
});
